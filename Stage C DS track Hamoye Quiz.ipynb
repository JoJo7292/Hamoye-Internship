{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #This guy removes warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = pd.read_csv('Data_for_UCI_named.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    6380\n",
       "stable      3620\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf['stabf'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "tau1     10000 non-null float64\n",
      "tau2     10000 non-null float64\n",
      "tau3     10000 non-null float64\n",
      "tau4     10000 non-null float64\n",
      "p1       10000 non-null float64\n",
      "p2       10000 non-null float64\n",
      "p3       10000 non-null float64\n",
      "p4       10000 non-null float64\n",
      "g1       10000 non-null float64\n",
      "g2       10000 non-null float64\n",
      "g3       10000 non-null float64\n",
      "g4       10000 non-null float64\n",
      "stab     10000 non-null float64\n",
      "stabf    10000 non-null object\n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dtf.isna().sum()\n",
    "\n",
    "dtf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = dtf.drop(['stab'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dtf.drop(columns=['stabf'])\n",
    "Y = dtf['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    5092\n",
       "stable      2908\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to balancing the classes. This is done to the train data only.\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=1)\n",
    "x_balanced, y_balanced = smote.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 12), (10184, 12))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have a balanced dataset,to check,\n",
    "x_train.shape, x_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000,), (10184,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    5092\n",
       "stable      5092\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_balanced.tolist()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() \n",
    "normalized_train = scaler.fit_transform(x_balanced) #using scalar on the train data\n",
    "normalized_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want them as dataframes with the line below\n",
    "normalized_train = pd.DataFrame(normalized_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_test = pd.DataFrame(normalized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.605895</td>\n",
       "      <td>0.214898</td>\n",
       "      <td>0.686826</td>\n",
       "      <td>0.945002</td>\n",
       "      <td>0.454782</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.874552</td>\n",
       "      <td>0.255448</td>\n",
       "      <td>0.545528</td>\n",
       "      <td>0.598331</td>\n",
       "      <td>0.669360</td>\n",
       "      <td>0.642234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.481097</td>\n",
       "      <td>0.525305</td>\n",
       "      <td>0.797470</td>\n",
       "      <td>0.027436</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.479547</td>\n",
       "      <td>0.065178</td>\n",
       "      <td>0.641255</td>\n",
       "      <td>0.414248</td>\n",
       "      <td>0.049680</td>\n",
       "      <td>0.912824</td>\n",
       "      <td>0.083403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075724</td>\n",
       "      <td>0.874245</td>\n",
       "      <td>0.355155</td>\n",
       "      <td>0.835240</td>\n",
       "      <td>0.474432</td>\n",
       "      <td>0.640493</td>\n",
       "      <td>0.697645</td>\n",
       "      <td>0.252484</td>\n",
       "      <td>0.903588</td>\n",
       "      <td>0.919622</td>\n",
       "      <td>0.198830</td>\n",
       "      <td>0.642306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.736693</td>\n",
       "      <td>0.652439</td>\n",
       "      <td>0.873580</td>\n",
       "      <td>0.171161</td>\n",
       "      <td>0.362461</td>\n",
       "      <td>0.278625</td>\n",
       "      <td>0.940452</td>\n",
       "      <td>0.691134</td>\n",
       "      <td>0.221930</td>\n",
       "      <td>0.893734</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>0.579607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.692014</td>\n",
       "      <td>0.088023</td>\n",
       "      <td>0.589553</td>\n",
       "      <td>0.764197</td>\n",
       "      <td>0.220544</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.911640</td>\n",
       "      <td>0.685474</td>\n",
       "      <td>0.983833</td>\n",
       "      <td>0.701163</td>\n",
       "      <td>0.828559</td>\n",
       "      <td>0.121206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.841058</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.051215</td>\n",
       "      <td>0.399379</td>\n",
       "      <td>0.979828</td>\n",
       "      <td>0.268636</td>\n",
       "      <td>0.556469</td>\n",
       "      <td>0.788209</td>\n",
       "      <td>0.735471</td>\n",
       "      <td>0.029041</td>\n",
       "      <td>0.975019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.949093</td>\n",
       "      <td>0.786564</td>\n",
       "      <td>0.461315</td>\n",
       "      <td>0.789597</td>\n",
       "      <td>0.394688</td>\n",
       "      <td>0.745914</td>\n",
       "      <td>0.405648</td>\n",
       "      <td>0.666724</td>\n",
       "      <td>0.139264</td>\n",
       "      <td>0.187933</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.562801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.839301</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>0.159799</td>\n",
       "      <td>0.212734</td>\n",
       "      <td>0.500281</td>\n",
       "      <td>0.488895</td>\n",
       "      <td>0.632927</td>\n",
       "      <td>0.394979</td>\n",
       "      <td>0.401137</td>\n",
       "      <td>0.153403</td>\n",
       "      <td>0.630950</td>\n",
       "      <td>0.810078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.455192</td>\n",
       "      <td>0.244438</td>\n",
       "      <td>0.391380</td>\n",
       "      <td>0.947911</td>\n",
       "      <td>0.817495</td>\n",
       "      <td>0.078118</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>0.230640</td>\n",
       "      <td>0.665037</td>\n",
       "      <td>0.157504</td>\n",
       "      <td>0.523852</td>\n",
       "      <td>0.710637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.804835</td>\n",
       "      <td>0.668408</td>\n",
       "      <td>0.247985</td>\n",
       "      <td>0.751894</td>\n",
       "      <td>0.613105</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.115533</td>\n",
       "      <td>0.391213</td>\n",
       "      <td>0.950579</td>\n",
       "      <td>0.044396</td>\n",
       "      <td>0.113866</td>\n",
       "      <td>0.273623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.605895  0.214898  0.686826  0.945002  0.454782  0.516700  0.874552   \n",
       "1  0.481097  0.525305  0.797470  0.027436  0.616162  0.479547  0.065178   \n",
       "2  0.075724  0.874245  0.355155  0.835240  0.474432  0.640493  0.697645   \n",
       "3  0.736693  0.652439  0.873580  0.171161  0.362461  0.278625  0.940452   \n",
       "4  0.692014  0.088023  0.589553  0.764197  0.220544  0.718310  0.911640   \n",
       "5  0.841058  0.000744  0.823204  0.051215  0.399379  0.979828  0.268636   \n",
       "6  0.949093  0.786564  0.461315  0.789597  0.394688  0.745914  0.405648   \n",
       "7  0.839301  0.016476  0.159799  0.212734  0.500281  0.488895  0.632927   \n",
       "8  0.455192  0.244438  0.391380  0.947911  0.817495  0.078118  0.302400   \n",
       "9  0.804835  0.668408  0.247985  0.751894  0.613105  0.688000  0.115533   \n",
       "\n",
       "         7         8         9         10        11  \n",
       "0  0.255448  0.545528  0.598331  0.669360  0.642234  \n",
       "1  0.641255  0.414248  0.049680  0.912824  0.083403  \n",
       "2  0.252484  0.903588  0.919622  0.198830  0.642306  \n",
       "3  0.691134  0.221930  0.893734  0.963154  0.579607  \n",
       "4  0.685474  0.983833  0.701163  0.828559  0.121206  \n",
       "5  0.556469  0.788209  0.735471  0.029041  0.975019  \n",
       "6  0.666724  0.139264  0.187933  0.010989  0.562801  \n",
       "7  0.394979  0.401137  0.153403  0.630950  0.810078  \n",
       "8  0.230640  0.665037  0.157504  0.523852  0.710637  \n",
       "9  0.391213  0.950579  0.044396  0.113866  0.273623  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.671365</td>\n",
       "      <td>0.380367</td>\n",
       "      <td>0.932340</td>\n",
       "      <td>0.821112</td>\n",
       "      <td>0.577835</td>\n",
       "      <td>0.068198</td>\n",
       "      <td>0.272932</td>\n",
       "      <td>0.954195</td>\n",
       "      <td>0.238500</td>\n",
       "      <td>0.837447</td>\n",
       "      <td>0.065691</td>\n",
       "      <td>0.813278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.558188</td>\n",
       "      <td>0.607557</td>\n",
       "      <td>0.445405</td>\n",
       "      <td>0.349467</td>\n",
       "      <td>0.466385</td>\n",
       "      <td>0.193555</td>\n",
       "      <td>0.621676</td>\n",
       "      <td>0.798284</td>\n",
       "      <td>0.028968</td>\n",
       "      <td>0.385755</td>\n",
       "      <td>0.908498</td>\n",
       "      <td>0.854065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.188048</td>\n",
       "      <td>0.408938</td>\n",
       "      <td>0.245239</td>\n",
       "      <td>0.504652</td>\n",
       "      <td>0.339393</td>\n",
       "      <td>0.531448</td>\n",
       "      <td>0.732018</td>\n",
       "      <td>0.712638</td>\n",
       "      <td>0.920287</td>\n",
       "      <td>0.084360</td>\n",
       "      <td>0.688470</td>\n",
       "      <td>0.014509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.475764</td>\n",
       "      <td>0.179892</td>\n",
       "      <td>0.606958</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.639912</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>0.616975</td>\n",
       "      <td>0.474772</td>\n",
       "      <td>0.523093</td>\n",
       "      <td>0.016780</td>\n",
       "      <td>0.397283</td>\n",
       "      <td>0.804946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.752247</td>\n",
       "      <td>0.914666</td>\n",
       "      <td>0.524646</td>\n",
       "      <td>0.993199</td>\n",
       "      <td>0.479150</td>\n",
       "      <td>0.496922</td>\n",
       "      <td>0.443090</td>\n",
       "      <td>0.637113</td>\n",
       "      <td>0.538482</td>\n",
       "      <td>0.075332</td>\n",
       "      <td>0.776320</td>\n",
       "      <td>0.263485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.367380</td>\n",
       "      <td>0.182863</td>\n",
       "      <td>0.880609</td>\n",
       "      <td>0.204729</td>\n",
       "      <td>0.630031</td>\n",
       "      <td>0.062436</td>\n",
       "      <td>0.240694</td>\n",
       "      <td>0.843188</td>\n",
       "      <td>0.858622</td>\n",
       "      <td>0.054766</td>\n",
       "      <td>0.026677</td>\n",
       "      <td>0.379814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.282216</td>\n",
       "      <td>0.987846</td>\n",
       "      <td>0.442622</td>\n",
       "      <td>0.749859</td>\n",
       "      <td>0.523287</td>\n",
       "      <td>0.471323</td>\n",
       "      <td>0.016242</td>\n",
       "      <td>0.963547</td>\n",
       "      <td>0.290968</td>\n",
       "      <td>0.932047</td>\n",
       "      <td>0.128253</td>\n",
       "      <td>0.665579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.061770</td>\n",
       "      <td>0.747826</td>\n",
       "      <td>0.738254</td>\n",
       "      <td>0.561700</td>\n",
       "      <td>0.394483</td>\n",
       "      <td>0.448693</td>\n",
       "      <td>0.592068</td>\n",
       "      <td>0.778058</td>\n",
       "      <td>0.735890</td>\n",
       "      <td>0.585056</td>\n",
       "      <td>0.831313</td>\n",
       "      <td>0.123828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.279011</td>\n",
       "      <td>0.435495</td>\n",
       "      <td>0.578258</td>\n",
       "      <td>0.839119</td>\n",
       "      <td>0.094441</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.880613</td>\n",
       "      <td>0.969781</td>\n",
       "      <td>0.913312</td>\n",
       "      <td>0.473574</td>\n",
       "      <td>0.487675</td>\n",
       "      <td>0.128482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.210660</td>\n",
       "      <td>0.272264</td>\n",
       "      <td>0.736220</td>\n",
       "      <td>0.176605</td>\n",
       "      <td>0.521946</td>\n",
       "      <td>0.694007</td>\n",
       "      <td>0.637163</td>\n",
       "      <td>0.123823</td>\n",
       "      <td>0.476920</td>\n",
       "      <td>0.060801</td>\n",
       "      <td>0.509959</td>\n",
       "      <td>0.324046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.671365  0.380367  0.932340  0.821112  0.577835  0.068198  0.272932   \n",
       "1  0.558188  0.607557  0.445405  0.349467  0.466385  0.193555  0.621676   \n",
       "2  0.188048  0.408938  0.245239  0.504652  0.339393  0.531448  0.732018   \n",
       "3  0.475764  0.179892  0.606958  0.008257  0.639912  0.026362  0.616975   \n",
       "4  0.752247  0.914666  0.524646  0.993199  0.479150  0.496922  0.443090   \n",
       "5  0.367380  0.182863  0.880609  0.204729  0.630031  0.062436  0.240694   \n",
       "6  0.282216  0.987846  0.442622  0.749859  0.523287  0.471323  0.016242   \n",
       "7  0.061770  0.747826  0.738254  0.561700  0.394483  0.448693  0.592068   \n",
       "8  0.279011  0.435495  0.578258  0.839119  0.094441  0.825040  0.880613   \n",
       "9  0.210660  0.272264  0.736220  0.176605  0.521946  0.694007  0.637163   \n",
       "\n",
       "         7         8         9         10        11  \n",
       "0  0.954195  0.238500  0.837447  0.065691  0.813278  \n",
       "1  0.798284  0.028968  0.385755  0.908498  0.854065  \n",
       "2  0.712638  0.920287  0.084360  0.688470  0.014509  \n",
       "3  0.474772  0.523093  0.016780  0.397283  0.804946  \n",
       "4  0.637113  0.538482  0.075332  0.776320  0.263485  \n",
       "5  0.843188  0.858622  0.054766  0.026677  0.379814  \n",
       "6  0.963547  0.290968  0.932047  0.128253  0.665579  \n",
       "7  0.778058  0.735890  0.585056  0.831313  0.123828  \n",
       "8  0.969781  0.913312  0.473574  0.487675  0.128482  \n",
       "9  0.123823  0.476920  0.060801  0.509959  0.324046  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_test.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=1)\n",
    "rfc.fit(normalized_train, y_balanced)\n",
    "Rand_Forest_pred = rfc.predict(normalized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA TREE FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree = ExtraTreesClassifier(random_state=1)\n",
    "extra_tree.fit(normalized_train, y_balanced)\n",
    "extraTree_pred = extra_tree.predict(normalized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XTRA GRADIENT BOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(random_state=1)\n",
    "XGB.fit(normalized_train, y_balanced)\n",
    "XGB_pred = XGB.predict(normalized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIGHT GRADIENT BOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM = LGBMClassifier(objective='binary', random_state=1)\n",
    "LGBM.fit(normalized_train, y_balanced)\n",
    "LGBM_pred = LGBM.predict(normalized_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPROVING THE EXTRA TREES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50,100,300,500,1000]\n",
    "min_samples_split = [2,3,5,7,9]\n",
    "min_samples_leaf = [1,2,4,6,8]\n",
    "max_features = ['auto', 'sqrt','log2',None]\n",
    "hyperparam_grid = {'n_estimators': n_estimators, 'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf, 'max_features': max_features}\n",
    "\n",
    "xtra_random = RandomizedSearchCV(estimator=extra_tree, cv=5, n_iter=10, n_jobs=-1, verbose=1, scoring='accuracy',\n",
    "                                 param_distributions=hyperparam_grid, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.5min finished\n"
     ]
    }
   ],
   "source": [
    "#fit the random search model\n",
    "xtra_random.fit(normalized_train, y_balanced)\n",
    "new_xtra_pred = xtra_random.predict(normalized_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCURACIES OF THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest model: 92.0\n",
      "Accuracy for improved Extra Trees model: 92.0\n",
      "Accuracy for XGBoost model: 94.0\n",
      "Accuracy for Light Gradient Boost model: 93.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, Rand_Forest_pred)\n",
    "print( 'Accuracy for Random Forest model: {}' .format(round(accuracy* 100 ), 2 ))\n",
    "\n",
    "accuracy = accuracy_score(y_test, new_xtra_pred)\n",
    "print( 'Accuracy for improved Extra Trees model: {}' .format(round(accuracy* 100 ), 2 ))\n",
    "\n",
    "accuracy = accuracy_score(y_test, XGB_pred)\n",
    "print( 'Accuracy for XGBoost model: {}' .format(round(accuracy* 100 ), 2 ))\n",
    "\n",
    "accuracy = accuracy_score(y_test, LGBM_pred)\n",
    "print( 'Accuracy for Light Gradient Boost model: {}' .format(round(accuracy* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Random Forest model: 95.0\n",
      "Precision for improved Extra Trees model: 95.0\n",
      "Precision for XGBoost model: 90.0\n",
      "Precision for Light Gradient Boost model: 89.0\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, Rand_Forest_pred, pos_label='unstable')\n",
    "print( 'Precision for Random Forest model: {}' .format(round(precision* 100 ), 2 ))\n",
    "\n",
    "precision = precision_score(y_test, new_xtra_pred, pos_label='unstable')\n",
    "print( 'Precision for improved Extra Trees model: {}' .format(round(precision* 100 ), 2 ))\n",
    "\n",
    "precision = precision_score(y_test, XGB_pred, pos_label='stable')\n",
    "print( 'Precision for XGBoost model: {}' .format(round(precision* 100 ), 2 ))\n",
    "\n",
    "precision = precision_score(y_test, LGBM_pred, pos_label='stable')\n",
    "print( 'Precision for Light Gradient Boost model: {}' .format(round(precision* 100 ), 2 ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECALL SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for Random Forest model: 92.0\n",
      "Recall for improved Extra Trees model: 91.0\n",
      "Recall for XGBoost model: 94.0\n",
      "Recall for Light Gradient Boost model: 92.0\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test, Rand_Forest_pred, pos_label='unstable')\n",
    "print( 'Recall for Random Forest model: {}' .format(round(recall* 100 ), 2 ))\n",
    "\n",
    "recall = recall_score(y_test, new_xtra_pred, pos_label='stable')\n",
    "print( 'Recall for improved Extra Trees model: {}' .format(round(recall* 100 ), 2 ))\n",
    "\n",
    "recall = recall_score(y_test, XGB_pred, pos_label='unstable')\n",
    "print( 'Recall for XGBoost model: {}' .format(round(recall* 100 ), 2 ))\n",
    "\n",
    "recall = recall_score(y_test, LGBM_pred, pos_label='stable')\n",
    "print( 'Recall for Light Gradient Boost model: {}' .format(round(recall* 100 ), 2 ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 for Random Forest model: 94.0\n",
      "F1 for improved Extra Trees model: 94.0\n",
      "F1 for XGBoost model: 94.0\n",
      "F1 for Light Gradient Boost model: 94.0\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, Rand_Forest_pred, pos_label='unstable')\n",
    "print( 'F1 for Random Forest model: {}' .format(round(f1* 100 ), 2 ))\n",
    "\n",
    "f1 = f1_score(y_test, Rand_Forest_pred, pos_label='unstable')\n",
    "print( 'F1 for improved Extra Trees model: {}' .format(round(f1* 100 ), 2 ))\n",
    "\n",
    "f1 = f1_score(y_test, Rand_Forest_pred, pos_label='unstable')\n",
    "print( 'F1 for XGBoost model: {}' .format(round(f1* 100 ), 2 ))\n",
    "\n",
    "f1 = f1_score(y_test, Rand_Forest_pred, pos_label='unstable')\n",
    "print( 'F1 for Light Gradient Boost model: {}' .format(round(f1* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE IMPORTANCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for improved Extra Trees model: 92.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, extraTree_pred)\n",
    "print( 'Accuracy for improved Extra Trees model: {}' .format(round(accuracy* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = extra_tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(normalized_train.columns, feat_imp)\n",
    "plt.xlabel('Feature Labels')\n",
    "plt.ylabel('Feat Importances')\n",
    "plt.title('Comparison results')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
